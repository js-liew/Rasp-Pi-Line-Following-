import os
import cv2
import numpy as np
import tensorflow as tf

# Set dataset path
dataset_path = r"C:\Users\kqjon\OneDrive\Desktop\dataset"  # Ensure this path is correct
image_size = (128, 128)  # Adjust as needed

# Function to load images
def load_data(dataset_path, image_size):
    X = []  # Image data
    y = []  # Labels
    class_names = []

    # Loop through folders (each representing a class)
    for label, class_name in enumerate(os.listdir(dataset_path)):
        class_path = os.path.join(dataset_path, class_name)
        
        if not os.path.isdir(class_path):  # Skip non-folder files
            continue
        
        class_names.append(class_name)

        for image_name in os.listdir(class_path):
            image_path = os.path.join(class_path, image_name)
            
            # Read the image
            img = cv2.imread(image_path, cv2.IMREAD_COLOR)  # Ensure color images
            
            if img is None:
                print(f"Warning: Unable to load image {image_path}, skipping...")
                continue  # Skip invalid images

            # Resize image
            img = cv2.resize(img, image_size)
            img = img / 255.0  # Normalize pixel values

            X.append(img)
            y.append(label)

    return np.array(X), np.array(y), class_names

# Load dataset
X, y, class_names = load_data(dataset_path, image_size)

# Check dataset size
print(f"Loaded {len(X)} images across {len(class_names)} classes.")

# Define a simple CNN model
model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(image_size[0], image_size[1], 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(len(class_names), activation='softmax')  # Output layer
])


# Compile the model
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(X, y, epochs=10, batch_size=32, validation_split=0.2)

# Save the trained model
model.save("symbol_recognition_model.h5")

print("Training complete. Model saved as 'symbol_recognition_model.h5'.")
