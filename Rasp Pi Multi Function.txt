from picamera2 import Picamera2
import cv2
import numpy as np
import RPi.GPIO as GPIO
from time import sleep
import tflite_runtime.interpreter as tflite

# === Motor & Encoder Setup ===
enA = 12
enB = 13
p1 = 27
p2 = 17
p3 = 22
p4 = 6
encoder1 = 26
encoder2 = 21

GPIO.setmode(GPIO.BCM)
GPIO.setwarnings(False)
GPIO.setup(p1, GPIO.OUT)
GPIO.setup(p2, GPIO.OUT)
GPIO.setup(p3, GPIO.OUT)
GPIO.setup(p4, GPIO.OUT)
GPIO.setup(enB, GPIO.OUT)
GPIO.setup(enA, GPIO.OUT)
GPIO.setup(encoder1, GPIO.IN, pull_up_down=GPIO.PUD_UP)
GPIO.setup(encoder2, GPIO.IN, pull_up_down=GPIO.PUD_UP)

pi_pwm = GPIO.PWM(enA, 1000)
pi_pwm2 = GPIO.PWM(enB, 1000)
pi_pwm.start(40)
pi_pwm2.start(40)

count = 0

#MODEL_PATH = "/home/jonliew/Desktop/TF_LITE/"
#LABELS_PATH = "/home/jonliew/Desktop/TF_LITE/"
MODEL_PATH = "/home/jonliew/Desktop/model_unquant.tflite"
LABELS_PATH = "/home/jonliew/Desktop/Desktop/labels.txt"

with open(LABELS_PATH, "r") as f:
    class_names = [line.strip() for line in f.readlines()]

interpreter = tflite.Interpreter(model_path=MODEL_PATH)
interpreter.allocate_tensors()

input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

IMG_SIZE = input_details[0]['shape'][1]

# === Motor Control Functions ===
def forward():
    GPIO.output(p1, GPIO.HIGH)
    GPIO.output(p2, GPIO.LOW)
    GPIO.output(p3, GPIO.HIGH)
    GPIO.output(p4, GPIO.LOW)

def back():
    GPIO.output(p1, GPIO.LOW)
    GPIO.output(p2, GPIO.HIGH)
    GPIO.output(p3, GPIO.LOW)
    GPIO.output(p4, GPIO.HIGH)

def right():
    GPIO.output(p1, GPIO.LOW)
    GPIO.output(p2, GPIO.HIGH)
    GPIO.output(p3, GPIO.HIGH)
    GPIO.output(p4, GPIO.LOW)

def left():
    GPIO.output(p1, GPIO.HIGH)
    GPIO.output(p2, GPIO.LOW)
    GPIO.output(p3, GPIO.LOW)
    GPIO.output(p4, GPIO.HIGH)

def stop():
    GPIO.output(p1, GPIO.LOW)
    GPIO.output(p2, GPIO.LOW)
    GPIO.output(p3, GPIO.LOW)
    GPIO.output(p4, GPIO.LOW)

import cv2
import numpy as np

def shape_detect(frame):
    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
    kernel = np.ones((5, 5), np.uint8)

    # Define masks for red, blue, and green
    red_mask1 = cv2.inRange(hsv, np.array([0,50,20]), np.array([10, 255, 255]))
    red_mask2 = cv2.inRange(hsv, np.array([160, 50, 20]), np.array([180,255,255]))
    red_mask = cv2.bitwise_or(red_mask1, red_mask2)

    blue_mask = cv2.inRange(hsv, np.array([94, 80, 2]), np.array([120, 255, 255]))
    green_mask = cv2.inRange(hsv, np.array([35, 52, 72]), np.array([80, 255, 255]))

    # Apply morphological operations to reduce noise
    red_mask = cv2.morphologyEx(cv2.dilate(red_mask, kernel), cv2.MORPH_OPEN, kernel)
    blue_mask = cv2.morphologyEx(cv2.dilate(blue_mask, kernel), cv2.MORPH_OPEN, kernel)
    green_mask = cv2.morphologyEx(cv2.dilate(green_mask, kernel), cv2.MORPH_OPEN, kernel)

    # Combine the red, blue, and green masks
    combined_mask = cv2.bitwise_or(red_mask, blue_mask)
    combined_mask = cv2.bitwise_or(combined_mask, green_mask)

# Create a white background
    white_background = np.full_like(frame, 255)  # same shape as frame, filled with white

# Use the mask to combine the original image and the white background
    filtered_frame = np.where(combined_mask[:, :, None] == 255, frame, white_background)

    cv2.imwrite("okok.jpg", filtered_frame)
    # Preprocess for model (assuming IMG_SIZE, interpreter, etc. are defined elsewhere)
    image = cv2.resize(filtered_frame, (IMG_SIZE, IMG_SIZE))
    image = np.expand_dims(image, axis=0).astype(np.float32)
    image = (image / 127.5) - 1
    
    interpreter.set_tensor(input_details[0]['index'], image)
    interpreter.invoke()

    output_data = interpreter.get_tensor(output_details[0]['index'])
    index = np.argmax(output_data)
    class_name = class_names[index]

    print(f"Detected: {class_name}")
    

# === Camera Setup ===
picam2 = Picamera2()
configure = picam2.create_preview_configuration(main={"size": (640, 480), "format": "RGB888"})
picam2.configure(configure)
picam2.start()

# === HSV Color Ranges ===
COLOR_RANGES = {
    'red':    [(0, 80, 100), (10, 255, 255)],
    'blue':   [(100, 150, 0), (140, 255, 255)],
    'green':  [(50, 70, 60), (80, 255, 255)],
    'yellow': [(20, 100, 100), (30, 255, 255)],
    'black':  [(0, 0, 0), (180, 255, 45)],
}

# === Helper Functions ===
def get_mask(hsv_frame, color):
    lower, upper = COLOR_RANGES[color]
    return cv2.inRange(hsv_frame, np.array(lower), np.array(upper))

def find_line_center(mask):
    M = cv2.moments(mask)
    if M["m00"] > 0:
        cx = int(M["m10"] / M["m00"])
        return cx
    return None

# === Main Loop ===
try:
    while True:
        frame1 = picam2.capture_array()
        frame = frame1[50:90, 100:520]  # Crop for region of interest
        frame2 = frame1[90:390, 100:480]
        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
        if count % 20 == 0:
            gray = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)
            _, binary = cv2.threshold(gray, 90, 250, cv2.THRESH_BINARY)
            contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            for contour in contours:
                area = cv2.contourArea(contour)
                perimeter = cv2.arcLength(contour, True)
                if area < 500 or perimeter < 1000:
                    continue
                approx = cv2.approxPolyDP(contour, 0.02 * perimeter, True)
                sides = len(approx)
                if sides > 9:
                    stop()
                    sleep(2)
                    shape_detect(frame1)
                else:
                    continue
        combined_mask = np.zeros_like(hsv[:, :, 0])
        
        for color in ['red', 'green']:
            combined_mask |= get_mask(hsv, color)

        # Fallback to black if no color detected
        cx = find_line_center(combined_mask)
        if cx is None:
            black_mask = get_mask(hsv, 'black')
            cx = find_line_center(black_mask)

        if cx is not None:
            center = frame.shape[1] // 2
            if cx < center - 50:
                left()
            elif cx > center + 50:
                right()
            else:
                forward()
finally:
    picam2.stop()


